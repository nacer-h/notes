\section{Data and Simulation}
\label{sec.data_mc}

\subsection{Data}
\label{sec.data_mc.data}

The data are organized into a number of "runs" that correspond to $\sim$ 2 hours of data collection. During the selected set of runs, the polarized photon beam was produced on a thin diamond radiator and passed through the collimator. The diamond was rotated between two perpendicular orientations, parallel and perpendicular polarizations, with respect to the floor. A small set of the selected runs are produced with unpolarized photon beam, using an aluminum radiator instead of the diamond radiator. Since the importance of having a large data sample to increase the probability of finding the $Y(2175)$ in photoproduction, all the different polarizations are combined in a dataset. The latest large datasets are used in this study: Spring 2017, Spring 2018 and Fall 2018.
~\par The CEBAF accelerator delivers a 250 MHz electron beam, corresponding to a beam bunch spacing of 4.008 ns, with different average intensities in the datasets. Due to the large quantity of data collection, and to efficiently store and process these data, a set of conditions were implemented to save only events of potential physics interest. These events that pass the trigger conditions are referred as triggers. For instance, a minimum energy deposition in the FCAL and/or BCAL is used to determine a good event, which is used in all the dataset triggers. A summary of the luminosity in the coherent peak region, the number of triggers, and the running conditions for the different datasets is presented in Tab.~\ref{tab.data_mc.data}.
~\par The triggered events are used to reconstruct the four-momentum vectors, positions of the tracks and showers, and many other important quantities, like particle identification information. After every improvement in reconstruction and calibration the data is processed again to produce the above quantities with a better precision. The latest reconstruction versions used in this analysis are: REST ver03, ver02 and ver02 corresponding to 2017, Spring 2018 and Fall 2018 datasets, respectively.

\begin{table}[H]
    \centering
    % \small
    \caption{Summary of GlueX Phase-I selected dataset}
    \label{tab.data_mc.data}
    \begin{tabular}{|c|c|c|c|c|c|c|}%|c|c|c|c|c|c|
        \hline
        \multirow{2}{*}{\thead{Run\\Period}} & \multirow{2}{*}{\thead{Coherent\\Peak\\Luminosity\\(pb$^-1$)}} & \multirow{2}{*}{\thead{Number\\of\\Triggers\\(x $10^9$)}} & \multicolumn{3}{c|}{Running Conditions} & \multirow{2}{*}{\thead{Analysis\\Launch}}\\ [1ex]
        \cline{4-6}
         & & & \thead{Beam\\Intensity\\(nA)} & \thead{Radiator\\Thickness\\($\mu$m)} & \thead{Collimator\\Diameter\\(mm)} & \\
        \cline{4-6}
        \hline
        2017 & 21.8 & 49.6 & 100, 150  & 58 & 5.0 & ver21 \\
        % \hline
        Spring 2018 & 58.4 & 146.0 & 50 - 250 & 17, 58 & 3.4, 5.0 & ver03 \\
        % \hline
        Fall 2018 & 39.2 & 80.14 & 450, 200 & 17, 47 & 5.0 & ver02 \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{Tagged Photon Flux}
\label{sec.data_mc.data_tag_flux}

The tagged photon flux for a data run period is determined using the hit coincidence between the PS and the TAGM or TAGH, including the PS acceptance correction. The tagged flux integrated over the run periods of the different datasets used in this study is shown in Fig.~\ref{fig.data_mc.data_tag_flux}. The data collected during the running experiment is not always recorded, due to detector and data acquisition limitations. Thus the measured photon flux has to account for the live time, the time that the data acquisition was ready to record events in the experiment, and correct the measured photon flux.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/ctot_tagged_flux.eps}
    \caption{\label{fig.data_mc.data_tag_flux}The tagged photon flux versus the photon beam energy distributions for 2017 (blue), Spring 2018 (red), and Fall 2018 (magenta) datasets.}
\end{figure}

\subsection{Monte Carlo Simulation}
\label{sec.data_mc.mc}

To understand our experimental data and obtain the event reconstruction efficiency, a Monte Carlo simulation (MC) is used. The MC samples are generated based on an isobar model, where a meson decays into two particles. The widths and masses of the generated particles are extracted from PDG data~\cite{Tanabashi18}, with the $Y(2175)$ parameters taken from a weighted data average over multiple experimental measurements. The generator produces four-vectors for a given topology, where the generated final state particles did not include any spin information. The generated beam energy distribution and the momentum transfer are based on the beam properties and t-slope from each datasets, respectively. Four samples for each reaction matching the corresponding year of data taking are generated, and a set of random triggers are included to simulate the detector noise during data collection for every run. The generated events were then passed through the modeled GlueX detectors based on Geant4, to simulate their response. In addition, the results were then smeared to model the detector resolution and efficiency. Finally, the simulated events were then reconstructed and analyzed in the same way as real data. A summary of theses samples with the number of generated events are shown in Tab.~\ref{tab.data_mc.mc}   

\begin{table}[H]
    \centering
    \caption{Monte Carlo samples}
    \label{tab.data_mc.mc}
    \begin{tabular}{|c|c|c|c|}
        \hline
        & 2017 & Spring 2018 & Fall 2018 \\
        \hline
        $\gamma p \rightarrow \phi \pi^+ \pi^- p$ & 22 M & 58 M & 38 M \\
        \hline
        $\gamma p \rightarrow Y(2175) p \rightarrow \phi \pi^+ \pi^- p$ & 22 M & 58 M & 38 M \\
        \hline
        $\gamma p \rightarrow \phi f_0 p$ & 22 M & 58 M & 38 M \\
        \hline
        $\gamma p \rightarrow Y(2175) p \rightarrow \phi f_0 p$ & 22 M & 58 M & 38 M \\
        \hline
        Reconstruction & ver03$\_$23 & ver02$\_$15 & ver02$\_$14 \\
        \hline
        Analysis & ver39 & ver13 & ver13 \\
        \hline
    \end{tabular}
\end{table}

